{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library와 framework의 차이는 제어 흐름에 대한 주도성이 누구에게 그리고 어디에 있는가에 있다. framework의 경우는 전체적인 흐름을 그 자체가 가지고 있어 사용자가 해당 framework 안에서 필요한 코드를 짜 넣는 구조이지만 library는 사용자가 그 흐름을 주도하여 필요한 library를 가져다가 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 인공지능의 한 분야로 경험을 통해 컴퓨터가 스스로 학습을 할 수 있게 해주는 알고리즘이다. 그리고 딥러닝은 마찬가지로 인공지능의 하위 개념이며 머신러닝에 속해있는 더 작은 개념이다. 딥러닝은 인공신경망 방법을 이용해 만든 머신러닝 기술이라고 할 수 있다.\n",
    "이 두 개념의 차이는 사람의 개입 여부이다. 머신러닝은 특징추출과 같이 데이터를 사람이 먼저 처리한다. 그리고 부정확한 예측에 대해 엔지니어가 개입하여 조정한다. 반면에 딥러닝은 이러한 과정이 생략되어 신경망을 통해 컴퓨터가 데이터를 기반으로 온전히 스스로 학습하고 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #cuda를 사용 가능하다면 device 명을 cuda로 아니면 cpu로 설정\n",
    "torch.manual_seed(45) #학습에서 random seed를 고정하기 위해 seed를 45로 제공함(cpu에서)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45) # 마찬가지로 seed를 모두 45로 고정하여 제공함.(cuda에서)\n",
    "print(device + \" is available\") # 위에서 falser가 나왔으므로 cpu가 device 값으로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # 학습률을 0.001로 설정\n",
    "batch_size = 100 # 배치 사이즈는 100으로 설정\n",
    "num_classes = 10 # 정답 클래스 개수를 10으로 설정\n",
    "epochs = 5 # 에포크는 5로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',     # 데이터의 저장위치\n",
    "    train = True,             # train_set으로 \n",
    "    download = True,          # 다운로드 여부\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터 전처리 작업(0에서 255까지 있는 값들을 0에서 1사이 값으로 변환)\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',     # 데이터 저장위치\n",
    "    train = False,            # test_set으로 (false)\n",
    "    download = True,          # 다운로드 여부\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터 전처리 작업(0에서 255까지 있는 값들을 0에서 1사이 값으로 변환)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 훈련할 데이터셋인 MNIST(숫자 이미지)를 torchvision을 통해 불러옴.\n",
    "# 해당 데이터들을 각각 train_set과 test_set으로 나눈 뒤 ToTensor를 통해 텐서로 변형해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "#앞선 dataset인 MNIST 데이터를 불러와 설정해준 batch_size 파라미터를 지정한 후 train_set과 test_set을 나눠 train_loader와 test_loader 생성.\n",
    "\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "# train_set의 shape를 통해 input 데이터의 size를 확인할 수 있음. 이는 [1, 28(높이), 28(너비)]의 shape를 가지고 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): # layer을 정의해주는 class를 생성\n",
    "        super(ConvNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # input = 1, output filter = 10, kernel_size = 5, padding = 0(기본값), stride = 1(기본값)인 첫번째 2차원 배열의 convolutional layer 생성\n",
    "                                                     # 이때 output size = ((28-5+2*0)/1)+1 = 24 즉 24x24로 변환시켜준다.\n",
    "                                                     # max pooling을 통해 12x12로 변환\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # input = 10, output filter = 10, kernel_size = 5, padding = 0(기본값), stride = 1(기본값)인 두번째 2차원 배열의 convolutional layer 생성\n",
    "                                                      # 이때 output size = ((12-5+2*0)/1)+1 = 8 즉 8x8로 변환시켜준다.\n",
    "                                                      # max pooling을 통해 4x4로 변환            \n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # dropout 레이어를 추가하여 노드가 0이 될 확률을 0.5로 하 오버피팅 방지를 위해 사용.\n",
    "        self.mp = nn.MaxPool2d(2) # 오버피팅을 방지하고 연산에 들어가는 자원을 줄이기 위해 사용(size가 2만큼 줄어들어 위의 max pooling 결과처럼 반으로 줄어들게 됨)\n",
    "        self.fc1 = nn.Linear(320,100) # 4x4x20 vector을 100개의 출력으로 변경\n",
    "        self.fc2 = nn.Linear(100,10)  # 100개의 출력을 10개의 출력으로 변경\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) # 첫번째 convolution layer relu를 적용하고 maxpool, 결과값은 12x12x10\n",
    "        x = F.relu(self.mp(self.conv2(x))) # 두번째 convolution layer relu를 적용하고 maxpool, 결과값은 12x12x10\n",
    "        x = self.drop2D(x) \n",
    "        x = x.view(x.size(0), -1) # 전결합층을 위해 flatten\n",
    "        x = self.fc1(x) # fc1 layer에 삽입\n",
    "        x = self.fc2(x) # fc2 layer에 삽입\n",
    "        return F.log_softmax(x) # fully-connected layer에 넣고 log softmax 함수에 적용해 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) # CNN 생성\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 비용함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 옵티마이저(Adam 옵티마이저 사용, 모델의 매개변수와 학습률 하이퍼파라미터 등록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cts08\\AppData\\Local\\Temp\\ipykernel_22544\\2022886463.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.338574588\n",
      "[Epoch:    2]  cost = 0.114702247\n",
      "[Epoch:    3]  cost = 0.0888829604\n",
      "[Epoch:    4]  cost = 0.0762760714\n",
      "[Epoch:    5]  cost = 0.0688434914\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): #epochs = 5 만큼 반복\n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device) # \n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad() # 모델의 gradient 값을 0으로 설정함.\n",
    "        hypothesis = model(data) # 모델을 forward pass하여 결과값을 저장함.\n",
    "        cost = criterion(hypothesis, target) # 저장한 output과 target의 loss를 계산하여 cost에 저장(비용함수)\n",
    "        cost.backward() # backward 함수로 gradient 계산\n",
    "        optimizer.step() # 모델 학습 파라미터 갱신\n",
    "        avg_cost += cost / len(train_loader) # loss를 변수에 누적하여 train_loader 개수로 나누어줌(평균계산)\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cts08\\AppData\\Local\\Temp\\ipykernel_22544\\2022886463.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  98.54 %\n"
     ]
    }
   ],
   "source": [
    "model.eval() # valuation 과정에서 사용하지 않아야 하는 layer을 off해줌. 즉, evaluate mode로 전환하여 dropout과 batch_normalization을 해제함.\n",
    "with torch.no_grad(): # grad를 해제함.(graident 값을 저장하지 않음)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] # 출력이 분류 각각에 대한 값으로 나타나기 때문에, 가장 높은 값을 갖는 인덱스를 추출\n",
    "        total += len(target) # 전체 클래스 개수\n",
    "        correct += (preds==target).sum().item() # 예측값과 실제값이 같은지 비교\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
